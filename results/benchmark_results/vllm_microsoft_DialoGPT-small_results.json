{
  "standard": {
    "model": "microsoft/DialoGPT-small",
    "phases": {},
    "metrics": [
      "InferenceMetrics(ttft=0.011046517998693162, tpot=0.01064840533338914, throughput=469.5538762336554, total_tokens=15, input_tokens=9, output_tokens=6, p50_latency=0.011046517998693162, p95_latency=0.011103774000730482, p99_latency=0.011103774000730482, gpu_memory_used=73885.0, gpu_utilization=32.0, cpu_utilization=0.0)",
      "InferenceMetrics(ttft=0.005003851998480968, tpot=0.00433422066635103, throughput=615.2586293931654, total_tokens=8, input_tokens=7, output_tokens=1, p50_latency=0.004073972000696813, p95_latency=0.005003851998480968, p99_latency=0.005003851998480968, gpu_memory_used=73885.0, gpu_utilization=0.0, cpu_utilization=0.7)",
      "InferenceMetrics(ttft=0.004783861000760226, tpot=0.0032809753332306477, throughput=812.76644772605, total_tokens=8, input_tokens=8, output_tokens=0, p50_latency=0.002598831999421236, p95_latency=0.004783861000760226, p99_latency=0.004783861000760226, gpu_memory_used=73885.0, gpu_utilization=3.0, cpu_utilization=0.7)",
      "InferenceMetrics(ttft=0.006040371999915806, tpot=0.0046578680000190316, throughput=500.9444950616462, total_tokens=7, input_tokens=6, output_tokens=1, p50_latency=0.003973771999881137, p95_latency=0.006040371999915806, p99_latency=0.006040371999915806, gpu_memory_used=73885.0, gpu_utilization=0.0, cpu_utilization=0.4)",
      "InferenceMetrics(ttft=0.0049022589992091525, tpot=0.003412817333204051, throughput=879.0391360276859, total_tokens=9, input_tokens=9, output_tokens=0, p50_latency=0.0027458639997348655, p95_latency=0.0049022589992091525, p99_latency=0.0049022589992091525, gpu_memory_used=73885.0, gpu_utilization=1.0, cpu_utilization=0.0)",
      "InferenceMetrics(ttft=0.01501872600056231, tpot=0.017014183666712295, throughput=313.4639567673076, total_tokens=16, input_tokens=6, output_tokens=10, p50_latency=0.017974235999645316, p95_latency=0.018049588999929256, p99_latency=0.018049588999929256, gpu_memory_used=73885.0, gpu_utilization=22.0, cpu_utilization=0.0)",
      "InferenceMetrics(ttft=0.004745653999634669, tpot=0.0033716920000491277, throughput=790.8986546303197, total_tokens=8, input_tokens=8, output_tokens=0, p50_latency=0.002685883000594913, p95_latency=0.004745653999634669, p99_latency=0.004745653999634669, gpu_memory_used=73885.0, gpu_utilization=3.0, cpu_utilization=0.0)",
      "InferenceMetrics(ttft=0.016766578000897425, tpot=0.016543165333738823, throughput=362.6875437050339, total_tokens=18, input_tokens=8, output_tokens=10, p50_latency=0.016766578000897425, p95_latency=0.017957019999812474, p99_latency=0.017957019999812474, gpu_memory_used=73885.0, gpu_utilization=0.0, cpu_utilization=0.0)",
      "InferenceMetrics(ttft=0.004766083999129478, tpot=0.003391745332919527, throughput=786.2225506097384, total_tokens=8, input_tokens=8, output_tokens=0, p50_latency=0.0027566899989324156, p95_latency=0.004766083999129478, p99_latency=0.004766083999129478, gpu_memory_used=73885.0, gpu_utilization=0.0, cpu_utilization=1.8)",
      "InferenceMetrics(ttft=0.004756879998240038, tpot=0.0033557876655928944, throughput=893.9778969805485, total_tokens=9, input_tokens=9, output_tokens=0, p50_latency=0.002690979999897536, p95_latency=0.004756879998240038, p99_latency=0.004756879998240038, gpu_memory_used=73885.0, gpu_utilization=3.0, cpu_utilization=0.4)"
    ],
    "system_info": {
      "gpu_memory_used": 4.0,
      "gpu_utilization": 0.0,
      "cpu_utilization": 0.0,
      "total_memory": 177.07050323486328,
      "available_memory": 171.10271835327148
    },
    "overall_metrics": "InferenceMetrics(ttft=0.011046517998693162, tpot=0.007001086066520656, throughput=1466.4391451723593, total_tokens=308, input_tokens=234, output_tokens=74, p50_latency=0.0047512669989373535, p95_latency=0.017974235999645316, p99_latency=0.018049588999929256, gpu_memory_used=73885.0, gpu_utilization=0.0, cpu_utilization=0.4)",
    "phase_breakdown": {
      "tokenization": 6.509999366244301e-07,
      "model_loading": 18.722394059999715,
      "prefill": 2.710003172978759e-07,
      "decode": 0,
      "output_processing": 0,
      "memory_operations": 0
    }
  },
  "concurrent": {
    "model": "microsoft/DialoGPT-small",
    "batch_size": 4,
    "concurrent_metrics": [
      "InferenceMetrics(ttft=0.015209683999273693, tpot=0.017587727000621573, throughput=758.1044061499314, total_tokens=40, input_tokens=30, output_tokens=10, p50_latency=0.018663894001292647, p95_latency=0.018889603001298383, p99_latency=0.018889603001298383, gpu_memory_used=73887.0, gpu_utilization=0.0, cpu_utilization=0.0)",
      "InferenceMetrics(ttft=0.018315278999580187, tpot=0.05595828133300529, throughput=291.88411338322527, total_tokens=49, input_tokens=31, output_tokens=18, p50_latency=0.019203526000637794, p95_latency=0.13035603899879789, p99_latency=0.13035603899879789, gpu_memory_used=73887.0, gpu_utilization=33.0, cpu_utilization=0.0)",
      "InferenceMetrics(ttft=0.0027958369992120424, tpot=0.004057801333450091, throughput=1396.4869644933206, total_tokens=17, input_tokens=17, output_tokens=0, p50_latency=0.0045629989999724785, p95_latency=0.004814568001165753, p99_latency=0.004814568001165753, gpu_memory_used=73887.0, gpu_utilization=0.0, cpu_utilization=0.0)"
    ],
    "system_info": {
      "gpu_memory_used": 73885.0,
      "gpu_utilization": 0.0,
      "cpu_utilization": 0.4,
      "total_memory": 177.07050323486328,
      "available_memory": 170.37128067016602
    }
  },
  "length_analysis": {
    "model": "microsoft/DialoGPT-small",
    "length_analysis": [
      {
        "input_length": 128,
        "metrics": "InferenceMetrics(ttft=0.009282152001105715, tpot=0.010021467999952923, throughput=964.5958722526557, total_tokens=29, input_tokens=20, output_tokens=9, p50_latency=0.009975345999919227, p95_latency=0.010806905998833827, p99_latency=0.010806905998833827, gpu_memory_used=73887.0, gpu_utilization=0.0, cpu_utilization=0.4)"
      },
      {
        "input_length": 256,
        "metrics": "InferenceMetrics(ttft=0.007126346999939415, tpot=0.008333794666517255, throughput=1919.8937147183758, total_tokens=48, input_tokens=38, output_tokens=10, p50_latency=0.0073737599996093195, p95_latency=0.010501277000003029, p99_latency=0.010501277000003029, gpu_memory_used=73887.0, gpu_utilization=4.0, cpu_utilization=0.4)"
      },
      {
        "input_length": 512,
        "metrics": "InferenceMetrics(ttft=0.0029685379995498806, tpot=0.0037703180005337344, throughput=6719.150302374253, total_tokens=76, input_tokens=76, output_tokens=0, p50_latency=0.0030376410013559507, p95_latency=0.005304775000695372, p99_latency=0.005304775000695372, gpu_memory_used=73887.0, gpu_utilization=3.0, cpu_utilization=0.0)"
      },
      {
        "input_length": 1024,
        "metrics": "InferenceMetrics(ttft=0.0028349879994493676, tpot=0.00375686566682513, throughput=13308.966685054309, total_tokens=150, input_tokens=150, output_tokens=0, p50_latency=0.0029797860006510746, p95_latency=0.005455823000374949, p99_latency=0.005455823000374949, gpu_memory_used=73887.0, gpu_utilization=0.0, cpu_utilization=0.0)"
      }
    ],
    "system_info": {
      "gpu_memory_used": 73887.0,
      "gpu_utilization": 0.0,
      "cpu_utilization": 0.0,
      "total_memory": 177.07050323486328,
      "available_memory": 170.37080001831055
    }
  }
}